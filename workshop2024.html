<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
  <meta name="keywords" content="hands,ECCV 2024,workshop,pose estimation,MANO,challenge,keypoint,gesture,robot,grasping,manipulation,hand tracking,motion capture">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />


  <link rel="stylesheet" href="main.css" type="text/css" />
  <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
  <!--- <title></title> --->
  <title>HANDS Workshop</title>
  <!-- MathJax -->

  <!-- End MathJax -->
</head>

<body>
  <div id="main-container">
    <div id="header-container">
      <div id="header">
        <div id="header-icon-text-container">
          <div id="header-text-container">
            <nav class="style1">
              <ul id="outer_list">
                <li id="outer_li_year"><a id="current_year" href="#">2024<span id="arrow"></span></a>
                  <ul id="top_list">
                    <!-- <li id="style2"><a id="style3" href="workshop2023.html">2023</a></li> -->
                    <li id="style2"><a id="style3" href="workshop2024.html">2024</a></li>
                  </ul>
                </li>

                <li id="outer_li"><a id="workshop_link" href="#">Workshop</a>
                </li>

                <li id="outer_li"><a id="challenge_link" href="#">Challenge</a>
                </li>

              </ul>
            </nav>
          </div>
        </div>

      </div>
      <div id="layout-content">
        <div id="text-img-container">
          <div id="img-container">
            <a href="https://hands-workshop.org/"><img src="./logos/hands.png" alt="HANDS" width="100%" /></a>
          </div>
          <div id="text-container"></div>
        </div>
        <p>
        <div id="beamer">
          <beam>
            Observing and Understanding <b>Hands</b> in Action
          </beam></br>
          <beams>
            in conjunction with ECCV 2024</br>
          </beams>
        </div>

        <br>
        <div id="menu-container">
          <div id="menu-item"><a id="style6" href="#overview">Overview</a></div>
          <div id="menu-item"><a id="style6" href="#schedule">Schedule</a></div>
          <div id="menu-item"><a id="style6" href="#papers">Submission</a></div>
          <div id="menu-item"><a id="style6" href="#speakers">Speakers</a></div>
          <div id="menu-item"><a id="style6" href="#organizers">Organizers</a></div>
          <div id="menu-item"><a id="style6" href="#sponsors">Sponsors</a></div>
          <div id="menu-item"><a id="style6" href="#contact">Contact</a></div>
        </div>
        <br>
        </p>
        <h1 id="overview">Overview </h1>
        <font size="5">
          Welcome to our HANDS@ECCV24.
        </font>
        </br>
        </br>
        <p>Our HANDS workshop will gather vision researchers working on perceiving hands performing actions, including
          2D
          &amp; 3D hand detection, segmentation, pose/shape estimation, tracking, etc. We will also cover related
          applications including gesture recognition, hand-object manipulation analysis, hand activity understanding,
          and
          interactive interfaces.</p>
        <p>The eighth edition of this workshop will emphasize the use of large foundation models (<i>e.g.</i> CLIP,
          Point-E, Segment Anything, Latent Diffusion Models) for hand-related tasks. These models have revolutionized
          the
          perceptions of AI, and demonstrate groundbreaking contributions to multimodal understanding, zero-shot
          learning,
          and transfer learning. However, there remains an untapped potential for exploring their applications in
          hand-related tasks. </p>


        <h1 id="schedule">Schedule</h1>
        <p>The HANDS workshop will be held in the afternoon on September 30th, 2024, at MiCo Milano.</p></br>
        <p> Other information will be released later. </p> 


        <h1 id="papers">Call for Papers</h1>

        <h2>Important Dates</h2>

         <table class="dataintable">
            <tbody>
                <tr>
                    <td><b>June 15, 2024 (Opened)</b></td>
                    <td>Paper Submission Start</td>
                </tr>
                  <tr>
                    <td><b>July 25, 2024 11:59 (Pacific Time)</b></td>
                        <td>Full Length Paper Submission Deadline</td>
                </tr>
                <tr>
                    <td><b>August 10, 2024, 11:59 (Pacific Time)</b></td>
                    <td>Full Length Paper Author Notification & Extended abstracts and Posters Submission Deadline</td>
                </tr>
                <tr>
                    <td><b>August 20, 2024, 11:59 (Pacific Time)</b></td>
                    <td>Camera-ready Submission</td>
                </tr>
            </tbody>
        </table>


        <h2>Topics</h2>
        We will cover all hand-related topics. The relevant topics include and not limited to:

        <ul id="topicstyle1">
          <li id="topicstyle2">Hand pose and shape estimation</li>
          <li id="topicstyle2">Hand & object interactions</li>
          <li id="topicstyle2">Hand detection/segmentation</li>
          <li id="topicstyle2">Hand gesture/action recognition</li>
          <li id="topicstyle2">4D hand tracking and motion capture</li>
          <li id="topicstyle2">Hand motion synthesis</li>
          <li id="topicstyle2">Hand modeling, rendering, generation</li>
          <li id="topicstyle2">Camera systems and annotation tools</li>
          <li id="topicstyle2">Novel algorithms and network architectures</li>
          <li id="topicstyle2">Multi-modal learning</li>
          <li id="topicstyle2">Self-/un-/weakly-supervised learning</li>
          <li id="topicstyle2">Generalization and adaptation</li>
          <li id="topicstyle2">Egocentric vision for AR/VR</li>
          <li id="topicstyle2">Robot grasping, object manipulation, Haptics</li>
        </ul>



        <h2>Submission Guidelines</h2>

        <b>Submission Website:</b> <a href="https://cmt3.research.microsoft.com/HANDS2024">https://cmt3.research.microsoft.com/HANDS2024</a>
        </br>
        </br>

        <p>We accept <b>full length papers</b>, <b>extended abstracts</b> and <b>posters</b> in our workshop. The full length submissions should be anonymized and will be one-round peer reviewed.  The accepted full length papers will be included in the ECCV24 conference proceedings, while others will only be presented in the workshop. We welcome papers that are accepted to the ECCV2024 main conference or previous conferences, and extended abstracts that in progress, to show the posters in our workshop.</p>

        <h3>Call for full length papers</h3>

        <p>Full length submissions should follow <a href="https://eccv2024.ecva.net/Conferences/2024/AuthorGuide">ECCV2024 submission policies</a> (no more than 14 pages) and use the official ECCV 2024 template. Note that the submissions violate the double-blind policy or the dual-submission policy will be rejected without review.</p>

        <h3>Call for extended abstracts and posters</h3>

        <p>Extended abstracts are not subject to the ECCV rules, and can use other templates. They should be shorter than the equivalent of 4 pages in CVPR template format. Note that extended abstracts are not anonymized, and will not be peer reviewed. Accepted extended abstracts will only publish on our website, show in our workshop and not appear in the ECCV24 conference proceedings. Posters can be simply submitted with PDF and their brief information like paper title, authors and conference name. </p>


        <h1 id="speakers">Invited Speakers</h1>
        <div id="member-container">
          <div id="member">
            <img src="./profiles/2024/shunsuke.jpg">
            <p>
              <b><a href="https://shunsukesaito.github.io">Shunsuke Saito</a></b></br>
              Reality Labs Research
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/shubham.jpg">
            <p>
              <b><a href="https://shubhtuls.github.io">Shubham Tulsiani</a></b></br>
              Carnegie Mellon University
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/yeqi.jpg">
            <p>
              <b><a href="https://person.zju.edu.cn/en/yeqi">Qi Ye</a></b></br>
              Zhejiang University
            </p>
          </div>
        </div>
        
        <h1 id="organizers">Organizers</h1>
        <p>
        <div id="member-container">
          <div id="member">
            <img src="./profiles/2024/hyung.jpg">
            <p>
              <b><a href="https://hyungjinchang.wordpress.com">Hyung Jin Chang</a></b></br>
              University of Birmingham
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/rongyu.jpg">
            <p>
              <b><a href="https://gloryyrolg.github.io">Rongyu Chen</a></b></br>
              National University of Singapore
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/zicong.png">
            <p>
              <b><a href="https://zc-alexfan.github.io">Zicong Fan</a></b></br>
              ETH Zurich
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/otmar.png">
            <p>
              <b><a href="https://ait.ethz.ch/people/hilliges">Otmar Hilliges</a></b></br>
              ETH Zurich
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/kun.png">
            <p>
              <b><a href="https://kunhe.github.io">Kun He</a></b></br>
              Meta Reality Labs
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/take.png">
            <p>
              <b><a href="https://tkhkaeio.github.io/">Take Ohkawa</a></b></br>
              University of Tokyo
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/yoichi.png">
            <p>
              <b><a href="https://sites.google.com/ut-vision.org/ysato/home">Yoichi Sato</a></b></br>
              University of Tokyo
            </p>
          </div>
            <div id="member">
            <img src="./profiles/2024/elden.jpg">
            <p>
              <b><a href="https://eldentse.github.io">Elden Tse</a></b></br>
              National University of Singapore
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/linlin.png">
            <p>
              <b><a href="https://mu4yang.com">Linlin Yang</a></b></br>
              Communication University of China
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/lixin.png">
            <p>
              <b><a href="https://lixiny.github.io">Lixin Yang</a></b></br>
              Shanghai Jiao Tong University
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/angela.png">
            <p>
              <b><a href="https://www.comp.nus.edu.sg/cs/people/ayao/">Angela Yao</a></b></br>
              National University of Singapore
            </p>
          </div>
          <div id="member">
            <img src="./profiles/2024/linguang.png">
            <p>
              <b><a href="https://lg-zhang.github.io/">Linguang Zhang</a></b></br>
              Facebook Reality Labs (Oculus)
            </p>
          </div>
        </div>
        </p>
        <h1 id="sponsors">Sponsors</h1>
        <div style="display: flex;margin-top: -100px;">
            <img style="max-height:64px; width: auto;height: auto; margin-right: 40px;" src="./profiles/2024/sponsor1.png">
            <img style="max-height:64px; width: auto;height: auto; margin-right: 10px;" src="./profiles/2024/sponsor2_1.svg"> 
            <img style="max-height:64px; width: auto;height: auto; margin-right: 20px;" src="./profiles/2024/sponsor2_2.png"> 
        </div>

        
        <h1 id="contact">Contact</h1>
        <p>hands2024@googlegroups.com</p>

        
        <div id="footer">
          <p style="align-items: center;text-align: center;">

            <a href="https://youtube.com/@handsworkshop" target="_Blank">
              <img id="page1" alt="" src="profiles/youtube.jpg">
            </a>
            <a href="https://github.com/handsworkshop" target="_Blank">
              <img id="page" alt="" src="profiles/github.png">
            </a>
          </p>
      </div>
      <script>


        document.getElementById('outer_li_year').addEventListener('click', function (event) {
          event.preventDefault(); // 阻止默认链接行为
          // 获取第一个<li>标签中的年份
          var year = document.querySelector('#outer_list > li:first-child > a').textContent.trim();
          // 构建新的href
          var newHref = 'workshop' + year + '.html';
          // 跳转到新的页面

          window.location.href = newHref;



        });
        document.getElementById('workshop_link').addEventListener('click', function (event) {
          event.preventDefault(); // 阻止默认链接行为
          // 获取第一个<li>标签中的年份
          var year = document.querySelector('#outer_list > li:first-child > a').textContent.trim();
          // 构建新的href
          var newHref = 'workshop' + year + '.html';
          // 跳转到新的页面
          window.location.href = newHref;

        });
        document.getElementById('challenge_link').addEventListener('click', function (event) {
          event.preventDefault(); // 阻止默认链接行为
          // 获取第一个<li>标签中的年份
          var year = document.querySelector('#outer_list > li:first-child > a').textContent.trim();
          // 构建新的href
          var newHref = 'challenge' + year + '.html';
          // 跳转到新的页面
          window.location.href = newHref;

        });
        // 获取所有带有id="style3"的a标签
        var yearLinks = document.querySelectorAll('#style3');

        yearLinks.forEach(function (link) {
          link.addEventListener('click', function (event) {
            event.preventDefault(); // 阻止默认链接行为

            // 获取点击的年份
            var selectedYear = this.textContent.trim();

            // 更新第一个li中的年份显示
            document.getElementById('current_year').textContent = selectedYear;

            // 关闭下拉菜单
            // document.getElementById('top_list').style.display = 'none';

            // 可选：如果需要，可以在这里添加跳转逻辑
            // window.location.href = this.href;
          });
        });
        var workshopLi = document.querySelector('#workshop_link');
        workshopLi.classList.add('highlight');
        // function highlightLinks() {
        //   var currentHref = window.location.href;
        //   alert("执行")
        //   alert(currentHref)
        //   if (currentHref.includes('workshop')) {
        //     var workshopLi = document.querySelector('#workshop_link');
        //     workshopLi.classList.add('highlight');
        //   } else if (currentHref.includes('challenge')) {
        //     var workshopLi1 = document.querySelector('#challenge_link');
        //     workshopLi1.classList.add('highlight');
        //   }
        // }
        // window.addEventListener('popstate', highlightLinks);
      </script>
</body>

</html>
