<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
  <meta name="keywords" content="hands,ECCV 2024,workshop,AssemblyHands,ARCTIC,OakInk2,UmeTrack,pose estimation,MANO,challenge,keypoint,gesture,robot,grasping,manipulation,hand tracking,motion capture">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <link rel="stylesheet" href="main.css" type="text/css" />
  <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
  <!--- <title></title> --->
  <title>HANDS Workshop</title>
  <!-- MathJax -->

  <!-- End MathJax -->
</head>

<body>
  <div id="main-container">
    <div id="header-container">
      <div id="header">
        <div id="header-icon-text-container">
          <div id="header-text-container">
            <nav class="style1">
              <ul id="outer_list">
                <li id="outer_li_year"><a id="current_year" href="#">2024<span id="arrow"></span></a>
                  <ul id="top_list">
                    <!-- <li id="style2"><a id="style3" href="workshop2023.html">2023</a></li> -->
                    <li id="style2"><a id="style3" href="workshop2024.html">2024</a></li>
                  </ul>
                </li>

                <li id="outer_li"><a id="workshop_link" href="#">Workshop</a>
                </li>

                <li id="outer_li"><a id="challenge_link" href="#">Challenge</a>
                </li>

              </ul>
            </nav>
          </div>
        </div>

      </div>
      <div id="layout-content">
        <div id="text-img-container">
          <div id="img-container">
            <a href="https://hands-workshop.org/"><img src="./logos/hands.png" alt="HANDS" width="100%" /></a>
          </div>
          <div id="text-container"></div>
        </div>
        <p>
        <div id="beamer">
          <beam>
            Observing and Understanding <b>Hands</b> in Action
          </beam></br>
          <beams>
            in conjunction with ECCV 2024</br>
          </beams>
        </div>
        <br>
        <div id="menu-container">
          <div id="menu-item"><a id="style6" href="#overview">Overview</a></div>
          <div id="menu-item"><a id="style6" href="#challenge1">AssemblyHands</a></div>
          <div id="menu-item"><a id="style6" href="#challenge2">ARCTIC</a></div>
          <div id="menu-item"><a id="style6" href="#challenge3">OakInk2</a></div>
          <div id="menu-item"><a id="style6" href="#challenge4">UmeTrack</a></div>
          <div id="menu-item"><a id="style6" href="#contact">Contact</a></div>
        </div>
        <br>
        </p>
        <h1 id="overview">Overview</h1>
        <p>We present the HANDS24 challenge for hands based on AssemblyHands, ARCTIC, OakInk2 and UmeTrack. To participate in the challenge, please fill the  <a href="https://forms.gle/cLnjFY2YFKBrw6kN7"><b>Google Form</b></a>  and accept the terms and conditions.</p>

        <h4 align="center">Winners and prizes will be announced and awarded during the workshop.</h4>
        <h4 align="center">Please see <b>General Rules and Participation</b> and <b>Four Tracks</b> below for more details.</h4>

        <h2>Timeline</h1>

        <table class="dataintable">
            <tbody>
                <tr>
                    <td><b>TBD</b></td>
                    <td>Challenge data & website release  & registration open</td>
                </tr>
                  <tr>
                    <td><b>TBD</b></td>
                        <td>Challenges start</td>
                </tr>
                <tr>
                    <td><b>TBD</b></td>
                    <td>Registration close</td>
                </tr>
                <tr>
                    <td><b>TBD</b></td>
                    <td>Challenge submission deadline</td>
                </tr>
                <tr>
                    <td><b>TBD</b></td>
                    <td>Decisions to participants</td>
                </tr>
                <tr>
                    <td><b>TBD</b></td>
                    <td>Technical Report Deadline</td>
                </tr>
            </tbody>
        </table>



        <h2>General Rules and Participation</h1>
        <p>We must follow the general challenge rules below and more rules can be found on each offical track page.</p>
        <ul>
          <li><p>To participate in the challenge, please fill the <a href="https://forms.gle/cLnjFY2YFKBrw6kN7"><b>Google Form</b></a> and accept the terms and conditions.</p>
            <ul>
            <li><p>Please <b>DO</b> use your institution's email address. Please <b>DO NOT</b> use your personal email address such as gmail.com, qq.com and 163.com.</p></li>
            <li><p>Each team must register under only one user id/email id. The list of team members <b>can not be changed or rearranged</b> throughout the competition.</p></li>
            <li><p>Each team should use the same email for creating accounts in the evaluation server, and use the team name (in verbatim) in the evaluation servers.</p></li>
            <li><p>Each individual can only participate in one team and should provide the institution email at registration.</p></li>
            <li><p>The team name should be formal and we preserve the rights to change the team name after discussing with teams.</p></li>
            <li><p>Each team will receive a registration email after registration.</p></li>
            <li><p>Teams found to be registered under multiple IDs will be disqualified.</p></li>
            <li><p>For any special cases, please email the organizers.</p></li>
            </ul>
          </li>

          <li><p>The primary contact email is important during registration.</p>
            <ul>
            <li><p>We will contact participants via emails once we have an important update.</p></li>
            <li><p>If there are any special reasons or ambiguities that may lead to disputes, please email the organizers first for explanation or approval. Subsequent contact may result in disqualification.</p></li>
            </ul>
          </li>

          <li><p>To encourage fair competition, different tracks may include limits like overall model size, training dataset etc. Details can be found in each track page.</p>
            <ul>
            <li><p>Teams may use any publicly available and appropriately licensed data (if allowed by the track) to train their models in addition to the ones provided by the organizers. </p></li>
            <li><p>The daily and overall submission number may be limited based on tracks.</p></li>
            <li><p>The best performance of a team <b>CAN NOT</b> be hidden during the competition. Hiding the best performance may result in warning or even disqualification.</p></li>
            <li><p>Any supervised/unsupervised training on the validation/testing set is not allowed in this competition.</p></li>
            </ul>
          </li>

            <li><p>Reproducibility is the responsibility of the winning teams and we invite all teams to advertise their methods.</p>
            <ul>
            <li><p>Winning methods should provide their source code to reproduce their results under strict confidentiality rules if requested by organizers/other participants. If the organizing committee determines that the submitted code runs with errors or does not yield results comparable to those in the final leaderboard and the team is not willing to cooperate, it will be disqualified, and the winning place will go to the next team in the leaderboard. </p></li>
            <li><p>In order for participants to be eligible for competition prizes and be included in the official rankings (to be presented during the workshop and subsequent publications), information about their submission must be provided to organizers. Information may include, but not limited to, details on their method, synthetic and real data use, architecture and training details. </p></li>
            <li><p>For each submission, participants must keep the parameters of their method constant across all testing data for a given track.</p></li>
            <li><p>To be considered a valid candidate in the competition, the method has to beat the baseline by a non-trivial margin. A method is invalid if there is no significant technical changes. For example, if you simply replace a ResNet18 backbone with a ResNet101 backbone, it is not counted as a valid method. The organizers preserve all rights to determine the validity of the method. We will invite all valid teams to advertise their methods via 2-3 page technical report, and or poster presentation.</p></li>
            <li><p>Winners should provide a 2-3 page technical report, winner talk, and poster presentation during the workshop.</p></li>
            </ul>
          </li>
        </ul>



        <h1 id="challenge1">AssemblyHands </h1>
        <p>We offer an extended version of the AssemblyHands challenge hosted in HANDS23. With increasing attention to multi-view AR/VR headsets (<i>e.g.</i> Apple Vision Pro, Meta Quest, etc.), we extend this realm to multi-view settings. Specifically, we benchmark a track for single-view-to-dual-view adaptation of 3D hand pose estimation using the AssemblyHands dataset.</p>

        <div style= "background-color: #e9e9e9; border: 1px solid black; text-align: center;">The Offical Website of AssemblyHands Track: TBD</div>

        <h1 id="challenge2">ARCTIC </h1>
        <p>Most methods for reconstructing hand-object interactions typically require a pre-scanned 3D object template, which is impractical for real-world scenarios. To address this, we host the category-agnostic reconstruction task where participants must reconstruct both hands and the object in 3D from a single video, without relying on pre-scanned templates. We offer 11 videos from the ARCTIC dataset's rigid object collection, one per object,  and sourced from the test set for this challenge.</p>

        <div style= "background-color: #e9e9e9; border: 1px solid black; text-align: center;">The Offical Website of ARCTIC Track: TBD</div>

        <h1 id="challenge3">OakInk2 </h1>
        <p>Synthesizing physically plausible hand-object interactions that leverage object functionalities remains to be a challenging task. We host the challenge where the participants need to synthesize hand trajectories capable of accomplishing specific task objectives within a designated simulation environment. The synthesis process will be based on a limited number of demonstrations of the same task, along with reference frames for the target environment. We identity tasks involving object relocation and manipulation from OakInk2 for this challenge.</p>

        <div style= "background-color: #e9e9e9; border: 1px solid black; text-align: center;">The Offical Website of OakInk2 Track: TBD</div>

        <h1 id="challenge4">UmeTrack </h1>
        <p>In XR applications, accurately estimating the hand poses from egocentric cameras is important to enable social presence and interactions with the environment. The problem of hand pose estimation on XR headsets presents unique challenges that differentiate it from existing problem statements. Participants will be provided with calibrated stereo hand crop videos and MANO shape parameters. The expected results in this challenge are MANO pose parameters and wrist transformations. The submitted pose parameters are supposed to be used in combination with the provided MANO shape parameters to calculate keypoints and MPJPE, in contrast to the existing protocol that allows the methods to directly produce tracking results in the form of 3D keypoints or full MANO parameters, which does not penalize undesirable changes in hand shape. Also, participants will be provided with calibrated stereo hand crop videos, assuming each video captures a single subject. The expected result is the MANO shape parameters, which will be evaluated using vertex errors in the neutral pose. </p>

        <p>This year, we are excited to launch two distinct tracks:</p>
        
        <ul>
        <li>Hand Shape Estimation: Determine the hand shape using calibrated stereo videos.</li>
        <li>Hand Pose Estimation: Track hand poses in calibrated stereo videos, utilizing pre-calibrated hand shapes.</li>
        </ul>

        <p>To encourage developing generalizable methods, we’ll adopt two datasets featuring different headset configurations: UmeTrack and HOT3D, the latter was recently introduced at CVPR</p>

        <div style= "background-color: #e9e9e9; border: 1px solid black; text-align: center;">

        <h4 align="center">Check out the following links to get started</h4>
        <h4 align="center">Challenge page: <a href="https://eval.ai/web/challenges/challenge-page/2333/overview"><b>https://eval.ai/web/challenges/challenge-page/2333/overview</b></a></h4>
        <h4 align="center">Hand Tracking Toolkit: <a href="https://github.com/facebookresearch/hand_tracking_toolkit"><b>https://github.com/facebookresearch/hand_tracking_toolkit</b></a></h4>
        <h4 align="center">UmeTrack dataset: <a href="https://huggingface.co/datasets/facebook/hand_tracking_challenge_umetrack"><b>https://huggingface.co/datasets/facebook/hand_tracking_challenge_umetrack</b></a></h4>

        </div>

        <h1 id="contact">Contact</h1>
        <p>hands2024@googlegroups.com</p>

        <div id="footer">
          <p style="align-items: center;text-align: center;">

            <a href="https://youtube.com/@handsworkshop" target="_Blank">
              <img id="page1" alt="" src="profiles/youtube.jpg">
            </a>
            <a href="https://github.com/handsworkshop" target="_Blank">
              <img id="page" alt="" src="profiles/github.png">
            </a>
          </p>
      </div>


      </div>

    </div>
    <script>
      document.getElementById('outer_li_year').addEventListener('click', function (event) {
        event.preventDefault(); // 阻止默认链接行为
        // 获取第一个<li>标签中的年份
        var year = document.querySelector('#outer_list > li:first-child > a').textContent.trim();
        // 构建新的href
        var newHref = 'workshop' + year + '.html';
        // 跳转到新的页面
        window.location.href = newHref;
      });
      document.getElementById('workshop_link').addEventListener('click', function (event) {
        event.preventDefault(); // 阻止默认链接行为
        // 获取第一个<li>标签中的年份
        var year = document.querySelector('#outer_list > li:first-child > a').textContent.trim();
        // 构建新的href
        var newHref = 'workshop' + year + '.html';
        // 跳转到新的页面
        window.location.href = newHref;
      });
      document.getElementById('challenge_link').addEventListener('click', function (event) {
        event.preventDefault(); // 阻止默认链接行为
        // 获取第一个<li>标签中的年份
        var year = document.querySelector('#outer_list > li:first-child > a').textContent.trim();
        // 构建新的href
        var newHref = 'challenge' + year + '.html';
        // 跳转到新的页面
        window.location.href = newHref;
      });
      // 获取所有带有id="style3"的a标签
      var yearLinks = document.querySelectorAll('#style3');

      yearLinks.forEach(function (link) {
        link.addEventListener('click', function (event) {
          event.preventDefault(); // 阻止默认链接行为

          // 获取点击的年份
          var selectedYear = this.textContent.trim();

          // 更新第一个li中的年份显示
          document.getElementById('current_year').textContent = selectedYear;

          // 关闭下拉菜单
          // document.getElementById('top_list').style.display = 'none';

          // 可选：如果需要，可以在这里添加跳转逻辑
          window.location.href = this.href;
        });
      });

      var workshopLi1 = document.querySelector('#challenge_link');
      workshopLi1.classList.add('highlight');
    </script>
</body>

</html>